feature,importance
judge_llama-3.3-70b-instruct-turbo_verdicts,0.22908724040719403
judge_claude-3-5-sonnet-latest_verdicts,0.1864147886349506
judge_gpt-4o_verdicts,0.07580697339953259
judge_qwen2.5-72b-instruct-turbo_verdicts,0.0716758705025736
judge_meta-llama-3.1-405b-instruct-turbo_verdicts,0.04220250775092004
grm_llama32_scores,0.03695405095087917
offset_bias_scores,0.036066565835436985
grm_gemma_scores,0.03437330462660094
judge_qwen2-72b-instruct_verdicts,0.027232874715995135
internlm_scores,0.026196530184143967
urm_scores,0.025357500482592082
armor_rm_verbosity,0.022264502747728603
qrm_scores,0.021290000569306092
gpm_scores,0.020980048646839472
armor_rm_score,0.01943996508354854
skyworks_scores,0.019343546168485916
armor_rm_complexity,0.017851764347464452
grm_scores,0.017794488520520343
armor_rm_correctness,0.016733186856881424
armor_rm_coherence,0.016434752537781625
armor_rm_helpfulness,0.01585281635712522
judge_llama-3.1-nemotron-70b-instruct-hf_verdicts,0.011192919450082947
judge_gemma-2-27b-it_verdicts,0.007870325989066358
judge_nous-hermes-2-mixtral-8x7b-dpo_verdicts,0.001583475234349859
judge_qwq-32b-preview_verdicts,0.0
judge_wizardlm-2-8x22b_verdicts,0.0
judge_mixtral-8x22b-instruct-v0.1_verdicts,0.0
