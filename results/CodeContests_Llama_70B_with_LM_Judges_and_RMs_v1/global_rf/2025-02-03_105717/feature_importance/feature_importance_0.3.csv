feature,importance
judge_llama-3.3-70b-instruct-turbo_verdicts,0.24526414499112165
judge_claude-3-5-sonnet-latest_verdicts,0.18612788948030948
judge_qwen2.5-72b-instruct-turbo_verdicts,0.07509366225190181
judge_meta-llama-3.1-405b-instruct-turbo_verdicts,0.05932737707170325
judge_gpt-4o_verdicts,0.053071892846704105
grm_gemma_scores,0.03373871705021433
judge_qwen2-72b-instruct_verdicts,0.033483996854529706
offset_bias_scores,0.03258376118617141
grm_llama32_scores,0.029145987706087804
urm_scores,0.025828022068747472
skyworks_scores,0.022392639780124048
gpm_scores,0.02167680110509213
internlm_scores,0.021434072891802304
qrm_scores,0.02018709320970121
armor_rm_verbosity,0.019216578761122413
armor_rm_score,0.018716893132199115
armor_rm_complexity,0.018670471765645496
armor_rm_correctness,0.01753510507472957
grm_scores,0.017237777207687353
armor_rm_helpfulness,0.016183401030309158
armor_rm_coherence,0.014335937087158503
judge_llama-3.1-nemotron-70b-instruct-hf_verdicts,0.009953188569049564
judge_gemma-2-27b-it_verdicts,0.007192421308297946
judge_nous-hermes-2-mixtral-8x7b-dpo_verdicts,0.0016021675695900386
judge_mixtral-8x22b-instruct-v0.1_verdicts,0.0
judge_wizardlm-2-8x22b_verdicts,0.0
judge_qwq-32b-preview_verdicts,0.0
