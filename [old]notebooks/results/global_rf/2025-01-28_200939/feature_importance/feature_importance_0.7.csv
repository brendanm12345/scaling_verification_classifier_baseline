feature,importance
judge_llama-3.3-70b-instruct-turbo_verdicts,0.24970546809336736
judge_claude-3-5-sonnet-latest_verdicts,0.17015886289342
judge_qwen2.5-72b-instruct-turbo_verdicts,0.10355060659847212
judge_meta-llama-3.1-405b-instruct-turbo_verdicts,0.061652596967473924
judge_gpt-4o_verdicts,0.05524600908322883
grm_gemma_scores,0.030943937805196827
grm_llama32_scores,0.029742459470295673
offset_bias_scores,0.028155588300927827
judge_qwen2-72b-instruct_verdicts,0.026673374968286964
urm_scores,0.023418080569167308
armor_rm_verbosity,0.021444378852521987
internlm_scores,0.020560285584188584
gpm_scores,0.019389746635457814
qrm_scores,0.01903630572798378
armor_rm_score,0.018165879917267373
skyworks_scores,0.01787086536783712
grm_scores,0.017312247800143867
armor_rm_complexity,0.017093794546343532
judge_llama-3.1-nemotron-70b-instruct-hf_verdicts,0.01588003839454604
armor_rm_correctness,0.014818590588445632
armor_rm_helpfulness,0.01369378564443445
armor_rm_coherence,0.013470682322079888
judge_gemma-2-27b-it_verdicts,0.010649391481924682
judge_nous-hermes-2-mixtral-8x7b-dpo_verdicts,0.0013670152080471766
judge_qwq-32b-preview_verdicts,7.17894118110822e-09
judge_wizardlm-2-8x22b_verdicts,0.0
judge_mixtral-8x22b-instruct-v0.1_verdicts,0.0
