feature,importance
judge_llama-3.3-70b-instruct-turbo_verdicts,0.26281849268876467
judge_claude-3-5-sonnet-latest_verdicts,0.17644575139569685
judge_qwen2.5-72b-instruct-turbo_verdicts,0.07752243025772414
judge_meta-llama-3.1-405b-instruct-turbo_verdicts,0.06083436256626862
judge_gpt-4o_verdicts,0.0527472530712297
offset_bias_scores,0.032061490036748276
judge_qwen2-72b-instruct_verdicts,0.03163175046868243
grm_gemma_scores,0.031103340386524164
grm_llama32_scores,0.029951431795452756
urm_scores,0.02610955400965209
armor_rm_verbosity,0.021456228669584798
internlm_scores,0.021325355907635866
skyworks_scores,0.02009227741358252
gpm_scores,0.0194182511927959
qrm_scores,0.019281728707614503
grm_scores,0.01848475232873427
armor_rm_score,0.018344930584524344
armor_rm_complexity,0.017831644486512532
armor_rm_correctness,0.016004192467460265
armor_rm_helpfulness,0.015090851247336662
armor_rm_coherence,0.014078336244881499
judge_llama-3.1-nemotron-70b-instruct-hf_verdicts,0.008324951837674482
judge_gemma-2-27b-it_verdicts,0.007469975497574715
judge_nous-hermes-2-mixtral-8x7b-dpo_verdicts,0.0015706667373440533
judge_mixtral-8x22b-instruct-v0.1_verdicts,0.0
judge_wizardlm-2-8x22b_verdicts,0.0
judge_qwq-32b-preview_verdicts,0.0
