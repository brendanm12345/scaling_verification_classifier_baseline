feature,importance
judge_llama-3.3-70b-instruct-turbo_verdicts,0.23558183689402418
judge_claude-3-5-sonnet-latest_verdicts,0.17393898288470697
judge_qwen2.5-72b-instruct-turbo_verdicts,0.08002557108635903
judge_meta-llama-3.1-405b-instruct-turbo_verdicts,0.05611744137133424
judge_gpt-4o_verdicts,0.05058103850942931
offset_bias_scores,0.039262988573714123
grm_llama32_scores,0.037097110638435904
grm_gemma_scores,0.03632901863770351
judge_qwen2-72b-instruct_verdicts,0.030626843085984057
internlm_scores,0.027195898614703472
urm_scores,0.02467391784196724
skyworks_scores,0.022451900837031077
qrm_scores,0.021639928180062266
gpm_scores,0.0214308659377153
armor_rm_verbosity,0.020741721969577465
armor_rm_score,0.020642949220122126
armor_rm_complexity,0.020042153477397125
armor_rm_coherence,0.01705119358454769
grm_scores,0.016299161333038204
armor_rm_helpfulness,0.016296265736628134
armor_rm_correctness,0.016151078922006883
judge_llama-3.1-nemotron-70b-instruct-hf_verdicts,0.008178352401513343
judge_gemma-2-27b-it_verdicts,0.005924137979704736
judge_nous-hermes-2-mixtral-8x7b-dpo_verdicts,0.0017196422822935548
judge_mixtral-8x22b-instruct-v0.1_verdicts,0.0
judge_wizardlm-2-8x22b_verdicts,0.0
judge_qwq-32b-preview_verdicts,0.0
